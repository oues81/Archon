"""
Exemple d'int√©gration de toutes les am√©liorations dans un graphe LangGraph.
D√©montre l'utilisation des nouveaux composants:
- Mod√®le Pydantic AgentState
- Gestion standardis√©e des erreurs LLM
- Instrumentation unifi√©e
- M√©canisme de checkpoint/reprise
"""
import os
import json
import asyncio
import logging
import sys
from typing import Dict, Any, Optional, List, Tuple
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

# Imports des nouveaux composants
from archon.state.agent_state import AgentState
from archon.state.checkpoint import checkpoint_state, restore_state
from archon.llm.error_handling import llm_error_handler
from archon.utils.instrumentation import time_node, log_graph_metrics

# Configuration du logging
logger = logging.getLogger(__name__)


# Exemples de n≈ìuds LangGraph instrument√©s avec les nouvelles fonctionnalit√©s
@time_node
async def analyzer_node(state: AgentState, config: Dict[str, Any]) -> AgentState:
    """
    N≈ìud d'analyse qui d√©termine les besoins de l'utilisateur.
    Utilise la gestion d'erreurs LLM standardis√©e.
    """
    logger.info(f"Analyse de la requ√™te utilisateur: {state.latest_user_message}")
    
    # Checkpoint avant traitement pour permettre la reprise
    checkpoint_id = await checkpoint_state(state, "analyzer_node", "example_flow")
    logger.info(f"√âtat sauvegard√© avec checkpoint ID: {checkpoint_id}")
    
    try:
        # Appel LLM avec le wrapper de gestion d'erreurs
        @llm_error_handler(provider="openai", model="gpt-4", max_retries=2)
        async def call_analysis_llm(prompt: str):
            # Simulation d'un appel LLM
            await asyncio.sleep(0.5)  # Simule la latence
            return "L'utilisateur souhaite cr√©er une application web avec une base de donn√©es."
        
        # Appel au LLM avec gestion d'erreurs
        analysis_result, metrics = await call_analysis_llm(state.latest_user_message)
        
        # Mettre √† jour l'√©tat avec le r√©sultat
        updated_state = state.model_copy()
        updated_state.scope = analysis_result
        
        # Ajouter les m√©triques LLM aux timings
        if "llm_metrics" not in updated_state.timings:
            updated_state.timings["llm_metrics"] = []
            
        updated_state.timings["llm_metrics"].append({
            "provider": metrics.provider,
            "model": metrics.model,
            "duration_ms": metrics.duration_ms,
            "success": metrics.success,
            "tokens_in": metrics.request_tokens,
            "tokens_out": metrics.response_tokens
        })
        
        return updated_state
        
    except Exception as e:
        # En cas d'erreur, l'√©tat contient d√©j√† l'information d'erreur gr√¢ce au d√©corateur time_node
        logger.error(f"Erreur dans analyzer_node: {e}")
        state.error = f"Erreur d'analyse: {str(e)}"
        return state


@time_node
async def planner_node(state: AgentState, config: Dict[str, Any]) -> AgentState:
    """
    N≈ìud de planification qui d√©finit les √©tapes n√©cessaires.
    """
    logger.info(f"Planification bas√©e sur l'analyse: {state.scope}")
    
    # Checkpoint avant traitement
    checkpoint_id = await checkpoint_state(state, "planner_node", "example_flow")
    
    try:
        # Simulation d'un traitement de planification
        await asyncio.sleep(0.3)
        
        # Mettre √† jour l'√©tat
        updated_state = state.model_copy()
        updated_state.refined_prompt = (
            "√âtapes de cr√©ation d'une application web avec base de donn√©es:\n"
            "1. D√©finir le sch√©ma de la base de donn√©es\n"
            "2. Cr√©er le backend API avec FastAPI\n"
            "3. Impl√©menter le frontend avec React\n"
            "4. Configurer le d√©ploiement Docker"
        )
        
        return updated_state
        
    except Exception as e:
        logger.error(f"Erreur dans planner_node: {e}")
        state.error = f"Erreur de planification: {str(e)}"
        return state


@time_node
async def generator_node(state: AgentState, config: Dict[str, Any]) -> AgentState:
    """
    N≈ìud de g√©n√©ration qui produit du code bas√© sur la planification.
    """
    logger.info(f"G√©n√©ration de code selon le plan")
    
    # Checkpoint avant traitement
    checkpoint_id = await checkpoint_state(state, "generator_node", "example_flow")
    
    try:
        # Appel LLM avec le wrapper de gestion d'erreurs
        @llm_error_handler(provider="openai", model="gpt-4", max_retries=2)
        async def call_generation_llm(prompt: str):
            # Simulation d'un appel LLM
            await asyncio.sleep(0.7)  # Simule la latence
            return """```python
from fastapi import FastAPI, Depends
from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session

# Configuration de la base de donn√©es
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Mod√®le de donn√©es
class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, index=True)
    email = Column(String, unique=True, index=True)

# Cr√©er les tables
Base.metadata.create_all(bind=engine)

# Application FastAPI
app = FastAPI()

# D√©pendance pour obtenir une session DB
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.post("/users/")
def create_user(name: str, email: str, db: Session = Depends(get_db)):
    user = User(name=name, email=email)
    db.add(user)
    db.commit()
    db.refresh(user)
    return user

@app.get("/users/")
def read_users(db: Session = Depends(get_db)):
    users = db.query(User).all()
    return users
```"""
        
        # Appel au LLM avec gestion d'erreurs
        code_result, metrics = await call_generation_llm(state.refined_prompt)
        
        # Mettre √† jour l'√©tat avec le r√©sultat
        updated_state = state.model_copy()
        updated_state.generated_code = code_result
        
        # Ajouter les m√©triques LLM aux timings
        if "llm_metrics" not in updated_state.timings:
            updated_state.timings["llm_metrics"] = []
            
        updated_state.timings["llm_metrics"].append({
            "provider": metrics.provider,
            "model": metrics.model,
            "duration_ms": metrics.duration_ms,
            "success": metrics.success,
            "tokens_in": metrics.request_tokens,
            "tokens_out": metrics.response_tokens
        })
        
        return updated_state
        
    except Exception as e:
        logger.error(f"Erreur dans generator_node: {e}")
        state.error = f"Erreur de g√©n√©ration: {str(e)}"
        return state


async def should_end(state: AgentState) -> str:
    """
    Fonction de condition pour d√©terminer si le workflow doit se terminer.
    """
    # Terminer si une erreur est survenue ou si le code a √©t√© g√©n√©r√©
    if state.error is not None:
        logger.info("Workflow termin√© avec erreur")
        return "end"
        
    if state.generated_code is not None:
        logger.info("Workflow termin√© avec succ√®s")
        return "end"
        
    # Continuer avec le workflow par d√©faut
    return "continue"


async def build_enhanced_graph():
    """
    Construit le graphe LangGraph avec les am√©liorations.
    """
    # Cr√©er le graphe avec le nouveau mod√®le Pydantic
    builder = StateGraph(AgentState)
    
    # Ajouter les n≈ìuds
    builder.add_node("analyzer", analyzer_node)
    builder.add_node("planner", planner_node)
    builder.add_node("generator", generator_node)
    
    # D√©finir le point d'entr√©e
    builder.set_entry_point("analyzer")
    
    # D√©finir les transitions
    builder.add_edge("analyzer", "planner")
    builder.add_edge("planner", "generator")
    
    # Ajouter la condition de fin
    builder.add_conditional_edges(
        "generator",
        should_end,
        {
            "end": END,
            "continue": "analyzer"  # Boucle si n√©cessaire
        }
    )
    
    # Compiler le graphe
    graph = builder.compile()
    
    return graph


async def run_example(user_input: str, resume_from: Optional[str] = None):
    """
    Ex√©cute le graphe avec les am√©liorations.
    
    Args:
        user_input: Message de l'utilisateur
        resume_from: ID de checkpoint pour reprendre un workflow
    """
    # Construire le graphe
    graph = await build_enhanced_graph()
    
    # Cr√©er l'√©tat initial ou restaurer depuis un checkpoint
    if resume_from:
        logger.info(f"Reprise du workflow depuis checkpoint: {resume_from}")
        initial_state = await restore_state(checkpoint_id=resume_from)
        if initial_state is None:
            logger.error(f"Impossible de restaurer le checkpoint: {resume_from}")
            initial_state = AgentState(
                latest_user_message=user_input,
                messages=[{"role": "user", "content": user_input}]
            )
    else:
        # Nouvel √©tat
        initial_state = AgentState(
            latest_user_message=user_input,
            messages=[{"role": "user", "content": user_input}]
        )
    
    # Ex√©cuter le graphe
    try:
        logger.info(f"D√©marrage du workflow pour: '{user_input}'")
        final_state = await graph.ainvoke(initial_state)
        
        # Logger les m√©triques finales
        log_graph_metrics(final_state)
        
        # V√©rifier le r√©sultat
        if final_state.error:
            logger.error(f"Workflow termin√© avec erreur: {final_state.error}")
            return {"status": "error", "error": final_state.error, "state": final_state.model_dump()}
            
        logger.info("Workflow termin√© avec succ√®s")
        return {
            "status": "success", 
            "result": {
                "scope": final_state.scope,
                "plan": final_state.refined_prompt,
                "code": final_state.generated_code
            },
            "metrics": final_state.timings,
            "state": final_state.model_dump()
        }
        
    except Exception as e:
        logger.error(f"Erreur lors de l'ex√©cution du workflow: {e}")
        return {"status": "error", "error": str(e)}


# Point d'entr√©e pour l'ex√©cution en standalone
async def main():
    """Point d'entr√©e pour l'ex√©cution du script."""
    # Configurer le logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    )
    
    # Exemple d'utilisation
    user_query = "Je veux cr√©er une application web pour g√©rer mes contacts avec une base de donn√©es."
    
    print(f"Ex√©cution du workflow pour: '{user_query}'")
    result = await run_example(user_query)
    
    if result["status"] == "success":
        print("\n‚úÖ WORKFLOW TERMIN√â AVEC SUCC√àS")
        print(f"\nSCOPE:\n{result['result']['scope']}")
        print(f"\nPLAN:\n{result['result']['plan']}")
        print(f"\nCODE:\n{result['result']['code']}")
        
        # Afficher les m√©triques de performance
        print("\nM√âTRIQUES DE PERFORMANCE:")
        for node_name, metrics in result["metrics"].items():
            if node_name != "llm_metrics":
                print(f"  ‚Ä¢ {node_name}: {metrics['duration_ms']:.2f}ms")
    else:
        print(f"\n‚ùå ERREUR: {result['error']}")
    
    # Exemple de reprise apr√®s erreur
    print("\nüîÑ SIMULATION D'UNE REPRISE DEPUIS UN CHECKPOINT")
    
    # Sauvegarder l'√©tat final comme checkpoint pour d√©monstration
    checkpoint_id = await checkpoint_state(
        result["state"], 
        "demo_checkpoint", 
        "example_flow", 
        ["demo"]
    )
    
    print(f"√âtat sauvegard√© avec checkpoint ID: {checkpoint_id}")
    print(f"Reprise du workflow depuis checkpoint: {checkpoint_id}")
    
    # Reprendre depuis le checkpoint
    resumed_result = await run_example("", resume_from=checkpoint_id)
    
    if resumed_result["status"] == "success":
        print("\n‚úÖ WORKFLOW REPRIS AVEC SUCC√àS")
    else:
        print(f"\n‚ùå ERREUR LORS DE LA REPRISE: {resumed_result['error']}")


if __name__ == "__main__":
    asyncio.run(main())
