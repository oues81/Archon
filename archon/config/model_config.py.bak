"""
Configuration des modèles LLM pour Archon AI.
Permet de configurer différents fournisseurs (Ollama, OpenRouter, etc.)
de manière dynamique via des variables d'environnement.
"""
import os
from typing import Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class ModelConfig:
    """Configuration pour un modèle LLM."""
    provider: str
    model_name: str
    base_url: str
    api_key: Optional[str] = None
    temperature: float = 0.7
    max_tokens: int = 2048
    headers: Optional[Dict[str, str]] = None

    @classmethod
    def from_env(cls, provider: str = None) -> 'ModelConfig':
        """Crée une configuration à partir des variables d'environnement."""
        provider = provider or os.getenv('LLM_PROVIDER', 'Ollama').lower()
        
        if provider == 'openrouter':
            # Pour OpenRouter, on utilise directement le modèle sans préfixe
            model_name = os.getenv('LLM_MODEL', 'deepseek/deepseek-chat-v3-0324:free')
            # Remove any prefixes including openrouter/
            model_name = model_name.replace('openrouter:', '').replace('openrouter/', '')
                
            return cls(
                provider='openrouter',
                model_name=model_name,
                base_url='https://openrouter.ai/api/v1',
                api_key=os.getenv('OPENROUTER_API_KEY'),
                headers={
                    "HTTP-Referer": "https://github.com/oues/archon",
                    "X-Title": "Archon AI Agent"
                }
            )
        else:  # Ollama par défaut
            return cls(
                provider='ollama',
                model_name=os.getenv('LLM_MODEL', 'qwen2.5:latest'),
                base_url=os.getenv('BASE_URL', 'http://host.docker.internal:11434'),
                temperature=float(os.getenv('TEMPERATURE', '0.7')),
                max_tokens=int(os.getenv('MAX_TOKENS', '2048'))
            )

    def to_dict(self) -> Dict[str, Any]:
        """Convertit la configuration en dictionnaire."""
        config = {
            'model': self.model_name,
            'temperature': self.temperature,
            'max_tokens': self.max_tokens
        }
        
        if self.provider == 'openrouter':
            config.update({
                'base_url': self.base_url,
                'api_key': self.api_key,
                'headers': self.headers
            })
        
        return config
